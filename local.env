# environment variables, source them to run the cluster locally
# Docker containers set appropriate values automatically during build

export PREFIX="$HOME/big-data"
echo
echo "Working in $PREFIX"

echo
echo "Setting environment variables..."
# hadoop
export HADOOP_HOME="$PREFIX/cluster/hadoop-2.8.5"
export HADOOP_PREFIX="${HADOOP_HOME}"
export HADOOP_INSTALL="${HADOOP_HOME}"
export HADOOP_MAPRED_HOME="${HADOOP_HOME}"
export HADOOP_COMMON_HOME="${HADOOP_HOME}"
export HADOOP_HDFS_HOME="${HADOOP_HOME}"
export YARN_HOME="${HADOOP_HOME}"
export HADOOP_COMMON_LIB_NATIVE_DIR="${HADOOP_HOME}/lib/native"

# hadoop-usage
export PATH="${PATH}:${HADOOP_HOME}/sbin:${HADOOP_HOME}/bin"
export HADOOP_OPTS="-Djava.library.path=${HADOOP_HOME}/lib/native"

# project-specific
export MASTER_HOST_NAME="$HOSTNAME"  # works on students
export CUSTOM_HDFS_DIR="$PREFIX/hdfsdata"
export CUSTOM_CLUSTER_DIR="$PREFIX/cluster"

# this is not actually necessary when running outside of docker
export FLAGS_DIR="$PREFIX/flags"

# applications directory where all user applications will be linked
# java applications can be compiled locally
# or remotely (in the cluster) as both sources and jars will be synchronized
export APPLICATIONS_DIR="$PREFIX/applications/"

env
